{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1268143-63da-4d72-a282-51aa20189f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import h5py\n",
    "import pandas as pd\n",
    "\n",
    "from astropy.cosmology import FlatLambdaCDM, z_at_value\n",
    "import astropy.units as u\n",
    "import astropy.cosmology.units as cu\n",
    "import astropy.constants as const\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.integrate import cumulative_trapezoid\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f0e916-9016-4085-b4d5-bb8bfbd45de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#at some point I should just make a Simulation class / object to store simulation name, boxsize, binsize, attributes, cosmology, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbbf747-4b14-4710-8857-594680645066",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = 'L35n270TNG'\n",
    "boxsize = 205000\n",
    "binsize = 500 #ckpc/h\n",
    "nbins = int(boxsize/binsize)\n",
    "outpath = f'n_e_maps/{args.sim}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ab7b5dd-51aa-43f9-816f-e229b1294317",
   "metadata": {},
   "outputs": [],
   "source": [
    "#when ray tracing through fine bins, we only need a (unordered) list of boxes (xyz) that the ray passes through\n",
    "#when ray tracing through coarse bins, we need to access which coarse bins (bin index) that the ray passes through + where it crosses\n",
    "#when ray tracing through sim boxes, we need to know which sim box (xyz) the the ray passes through + where it crosses\n",
    "\n",
    "#returns ordered list of box crossings: coordinates where the ray enters that box, plus dest\n",
    "#assumes that edges are located at integer multiples of boxsize\n",
    "\n",
    "def get_box_crossings(dest, origin, boxsize): \n",
    "    \n",
    "    edges_list = [dest]\n",
    "    edge_dists_list = [norm(dest-origin)]\n",
    "    \n",
    "    for i in range(3): #loop over dimensions, get all edge crossings in each dimension\n",
    "        x_f = dest[i]\n",
    "        x_0 = origin[i]\n",
    "        if (x_f//boxsize) == (x_0//boxsize): #no edge crossings\n",
    "            continue\n",
    "            \n",
    "        unit_vec_i = (dest - origin)/(x_f - x_0)\n",
    "        edge_1 = origin + unit_vec_i * (boxsize - x_0%boxsize)\n",
    "        \n",
    "        q = (x_f - edge_1[i]) // boxsize + 1 # no. of total edge crossings in the x-direction\n",
    "        \n",
    "        edges = edge_1 + np.atleast_2d(unit_vec_i) * boxsize * np.atleast_2d(np.arange(q)).T\n",
    "        edges_list.append(edges)\n",
    "        edge_dists_list.append(norm(edges - origin, axis=1))\n",
    "        \n",
    "    all_edges = np.unique(np.vstack(edges_list))\n",
    "    all_dists = np.concatenate(edge_dists_list)\n",
    "\n",
    "    all_dists, index_arr = np.unique(all_dists, return_index=True)\n",
    "    all_edges = all_edges[index_arr]\n",
    "    all_box_gridcoords = np.array(all_edges // boxsize, type=int)\n",
    "    \n",
    "    return all_edges, all_edge_dists, all_box_gridcoords\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402cfd7f-0ae9-4e16-81f9-4126a661b454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ray_trace(dest, origin, boxsize, binsize, n_bins, snap_xs):\n",
    "    \n",
    "    x_edges = [0] #edge positions: for riemann integration\n",
    "    xs = [] #bin midpoints, for calculating redshift, n_e(x), etc.\n",
    "    nes = [] #electron density in (ckpc/h)**-3\n",
    "    \n",
    "    Vcell = binsize**3\n",
    "    \n",
    "    sim_box_edges, sim_box_edge_dists, sim_box_gridcoords = get_box_crossings(dest, origin, boxsize)\n",
    "    current_pos = origin\n",
    "    traveled_dist = 0\n",
    "    \n",
    "    open_snap = 99\n",
    "    open_map = np.load(os.path.join(outpath, '99.npy'))\n",
    "    \n",
    "    for box_idx in range(len(n_sim_boxes)):\n",
    "        \n",
    "        offset = boxsize * sim_box_gridcoords #offset sim box coordinates\n",
    "        next_pos = sim_box_edges[box_idx]\n",
    "        \n",
    "        current_pos -= offset\n",
    "        next_pos -= offset\n",
    "        \n",
    "        bin_edges, bin_edge_dists, bin_gridcoords = get_box_crossings(next_pos, current_pos, binsize)\n",
    "        bin_edge_dists += traveled_dist\n",
    "        bin_mid_dists = np.convolve( np.concatenate([traveled_dist, bin_edge_dists]), [0.5, 0.5], 'valid' )\n",
    "        \n",
    "        bin_indices = bin_gridcoords[:, 0] * n_bins**2 + bin_gridcoords[:, 1] * n_bins + bin_gridcoords[:, 2]\n",
    "        bin_snaps = (np.abs(np.repeat(bin_mid_dists, 100, axis=0).T - snap_xs)).argmin(axis=0) #find closest snapshot for each bin\n",
    "        \n",
    "        for bidx in range(len(bin_edges)-1): #loop through bins\n",
    "            snap = bin_snaps[bidx]\n",
    "            if snap != open_snap: #if corresponding snapshot is not open, open it\n",
    "                open_snap = snap\n",
    "                open_map = np.load(os.path.join(outpath, f'{snap}.npy'))\n",
    "            \n",
    "            x_edges.append(bin_edge_dists[bin_idx])\n",
    "            xs.append(bin_mid_dists[bin_idx])\n",
    "            nes.append(open_map[bin_indices[bidx]] / Vcell)\n",
    "        \n",
    "        current_pos = next_pos\n",
    "        traveled_dist = sim_box_edge_dists[box_idx]\n",
    "    \n",
    "    return np.array(x_edges), np.array(xs), np.array(nes) \n",
    "    #returns n_e(x) where x is in ckpc/h, n_e is in (ckpc/h)**3, in order of increasing comoving distance (x)\n",
    "    #x_edges is 1 longer than nes\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376f1bf8-d8a7-4980-a383-10bfbc76ea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_DM(x_edges, xs, nes, dist, cumulative=False):\n",
    "    \n",
    "    nes = nes.to(u.cm**(-3), h_equiv)\n",
    "    zs = z_from_dist(xs)\n",
    "    \n",
    "    y = nes * (1 + zs) \n",
    "    dx = np.diff( (x_edges * u.kpc/cu.littleh).to(u.pc, h_equiv) )\n",
    "    \n",
    "    if cumulative:\n",
    "        return np.cumsum(np.flip(y * dx)) #integrate from FRB to observer\n",
    "        #plot with xs (bin midpoints)\n",
    "    else:\n",
    "        return np.sum(y * dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cbbd631-0885-494a-b48d-de4003b39924",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set basepath and retrieve relevant cosmological parameters\n",
    "\n",
    "# sim = 'L205n1250TNG'\n",
    "sim = 'L35n270TNG'\n",
    "basepath = f'/home/tnguser/sims.TNG/{sim}/output'\n",
    "datapath = f'n_e_maps/{sim}'\n",
    "\n",
    "with h5py.File(os.path.join(basepath, 'snapdir_099/snap_099.0.hdf5')) as f:\n",
    "    header = dict(f['Header'].attrs)\n",
    "\n",
    "boxsize = int(header['BoxSize'])\n",
    "h = header['HubbleParam']\n",
    "Omega0 = header['Omega0']\n",
    "\n",
    "cosmo = FlatLambdaCDM(H0=100*h, Om0=Omega0)\n",
    "h_equiv = cu.with_H0(cosmo.H0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7a1b0d-e9f4-4340-87d4-3e7021bc691c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create interpolant for determining redshifts from comoving distances\n",
    "dist_max = 1e7 # u.kpc / cu.littleh\n",
    "dist_vals = np.linspace(1, dist_max, 10000)\n",
    "redshift_vals = np.asarray([z_at_value(cosmo.comoving_distance, dist*h*u.kpc) for dist in dist_vals])\n",
    "z_from_dist = interp1d(dist_vals, redshift_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3704239-b45b-4d3d-b2a0-f8b568fe3082",
   "metadata": {},
   "outputs": [],
   "source": [
    "snap_zs = []\n",
    "for snap in range(100):\n",
    "    with h5py.File(get_chunk_path(snap)) as f:\n",
    "        zs.append(f['Header'].attrs['Redshift'])\n",
    "snap_zs = np.array(snap_zs) * cu.redshift\n",
    "snap_xs = cosmo.comoving_distance(zs).to(u.kpc) / cu.littleh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22a0692b-01de-481b-89c6-189f75ac5416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([0,1,2]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fc56d2-352e-4dc5-bbbc-77032b82241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_to_line(point, line, line_len): #shortest distance from vector from origin to 'point', to the line between the origin and 'line'\n",
    "    return norm(np.cross(point, line), axis=1) / line_len\n",
    "\n",
    "def dist_along_line(point, line, line_len):\n",
    "    return np.dot(point, line) / line_len\n",
    "\n",
    "def get_interp_data_from_snap(snap, vec_0, dist_0, vec_1, dist_1, start_time): #interpolates between snapshot snap and snap+1\n",
    "    snap_df = pd.DataFrame()\n",
    "    for chunk in range(snap_info['NumChunks'][snap]): #iterate through chunks\n",
    "        print(f'{time.time()-start_time:<7.2f}:    Reading file {get_chunk_path(snap, chunk)}')\n",
    "        chunk_df_0 = get_data_from_chunk(get_chunk_path(snap, chunk), vec_0, vec_1 - vec_0, dist_1 - dist_0) #corresponds to snapshot snap\n",
    "        print(f'{time.time()-start_time:<7.2f}:    Reading file {get_chunk_path(snap+1, chunk)}')\n",
    "        chunk_df_1 = get_data_from_chunk(get_chunk_path(snap+1, chunk), vec_0, vec_1 - vec_0, dist_1 - dist_0) #corresponds to snapshot snap+1\n",
    "        #interpolate between chunk_df_0 and chunk_df_1, weighting by distance\n",
    "        dists = (np.array(chunk_df_1['Comoving Distance']) + np.array(chunk_df_0['Comoving Distance'])) / 2 #we will weight by the average comoving dist over these two snapshots\n",
    "        interp_df = (chunk_df_1 - chunk_df_0)/(dist_1 - dist_0)*(dists - dist_0) + chunk_df_0\n",
    "        interp_df.dropna(inplace=True)\n",
    "        snap_df = pd.concat((snap_df, interp_df))\n",
    "    return snap_df\n",
    "    \n",
    "def get_los_with_interp(dest, origin, radius=200, basepath=basepath, save_hdf=None):\n",
    "    \n",
    "    dest = np.array(dest)\n",
    "    origin = np.array(origin)\n",
    "    \n",
    "    vec_0 = np.array(origin)\n",
    "    dist_0 = norm(vec_0)\n",
    "    total_vec = dest - origin\n",
    "    total_dist = norm(total_vec)\n",
    "    unit_vec = total_vec / total_dist\n",
    "    \n",
    "    res = pd.DataFrame()\n",
    "    #ray trace through snapshots\n",
    "    start_time = time.time()\n",
    "    snap = 99\n",
    "    \n",
    "    while dist_0 < total_dist: \n",
    "        \n",
    "        print(f'{time.time()-start_time:<7.2f}: Snapshot {snap}')\n",
    "        \n",
    "        dist_1 = min((snap_info['Comoving Distance'][snap-1], total_dist))\n",
    "        vec_1 = origin + dist_1 * unit_vec\n",
    "        print(f'Going from {vec_0} to {vec_1}')\n",
    "    \n",
    "        res = pd.concat(res, get_interp_data_from_snap(snap, vec_0, dist_0, vec_1, dist_1, start_time)) #interpolated between snapshots snap and snap+1\n",
    "        \n",
    "        snap -= 1\n",
    "        dist_0, vec_0 = dist_1, vec_1\n",
    "    \n",
    "    res = res[~res.index.duplicated(keep='last')]\n",
    "    header = pd.Series({'basepath': basepath, 'dest': dest, 'origin': origin, 'radius': radius, 'params': params})\n",
    "    if save_hdf:\n",
    "        res.to_hdf(save_hdf, key='data')\n",
    "        header.to_hdf(save_hdf, key='header')\n",
    "    \n",
    "    print(f'Total Time: {time.time()-start_time:<7.2f}')\n",
    "    return res, header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b042b0-93ee-41ae-8a63-e5bc2695d544",
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = []\n",
    "numchunks = []\n",
    "for i in range(99, -1, -1):\n",
    "    with h5py.File(il.snapshot.snapPath(basepath, i)) as f:\n",
    "        zs.append(f['Header'].attrs['Redshift'])\n",
    "        numchunks.append(f['Header'].attrs['NumFilesPerSnapshot'])\n",
    "zs = np.array(zs) * cu.redshift\n",
    "xs = cosmo.comoving_distance(zs).to(u.kpc) / cu.littleh\n",
    "half_dists = np.convolve(xs, np.array([0.5, 0.5]))[1:] #cutoff at halfway comoving distance between different snapshot redshifts\n",
    "half_dists[-1] = xs[-1]\n",
    "\n",
    "snap_info = pd.DataFrame(data = {'NumChunks': numchunks, 'Redshift': zs, 'Comoving Distance': xs, 'Halfway Distances': dist_cutoffs}, \n",
    "                         index=range(99, -1, -1))\n",
    "snap_info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
